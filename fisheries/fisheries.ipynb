{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jared/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jared/courses/deeplearning2/Kaggle/fisheries/data\n"
     ]
    }
   ],
   "source": [
    "%cd data\n",
    "\n",
    "data_dir = %pwd\n",
    "train_dir = data_dir + '/train/'\n",
    "valid_dir = data_dir + '/valid/'\n",
    "test_dir = data_dir + '/test/'\n",
    "sample_dir = data_dir + '/sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "num_sample = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Flatten, Convolution2D, MaxPooling2D, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#base_dir = sample_dir\n",
    "path = data_dir + '/'\n",
    "batch_size = 64\n",
    "image_size = (224,224)\n",
    "image_shape = (*image_size, 3)\n",
    "\n",
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    files = glob(train_dir + cls + '/*.jpg')\n",
    "    \n",
    "    num_valid = int(len(files) * .2)\n",
    "    \n",
    "    np.random.shuffle(files)\n",
    "    \n",
    "    os.mkdir(sample_dir + 'train/' + cls)\n",
    "    for file in files[:num_sample]:\n",
    "        copyfile(file, sample_dir + 'train/' + cls + '/' + os.path.basename(file))\n",
    "    \n",
    "    os.mkdir(sample_dir + 'valid/' + cls)\n",
    "    for file in files[num_sample:num_sample+num_sample]:\n",
    "        copyfile(file, sample_dir + 'valid/' + cls + '/' + os.path.basename(file))\n",
    "    \n",
    "    os.mkdir(valid_dir + cls)\n",
    "    for file in files[:num_valid]:\n",
    "        os.rename(file, valid_dir + cls + '/' + os.path.basename(file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3025 images belonging to 8 classes.\n",
      "Found 752 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "val_gen = ImageDataGenerator()\n",
    "\n",
    "batches = gen.flow_from_directory(path+'train/', target_size=image_size, batch_size=batch_size, shuffle=True)\n",
    "val_batches = val_gen.flow_from_directory(path+'valid/', target_size=image_size, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_steps = (batches.n//batch_size) + 1\n",
    "val_steps = (val_batches.n//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 109, 109, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 54, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 373248)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              382206976 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 382,290,836\n",
      "Trainable params: 382,290,830\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    BatchNormalization(input_shape=image_shape)\n",
    "    , Convolution2D(64, (3,3), activation='relu')\n",
    "    , MaxPooling2D((2,2))\n",
    "    , Convolution2D(128, (3,3), activation='relu')\n",
    "    , MaxPooling2D((2,2))\n",
    "    , Flatten()\n",
    "    , Dense(1024, activation='relu')\n",
    "    , Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 0.00001\n",
    "model.fit_generator(batches, train_steps, epochs=1, validation_data=val_batches, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
